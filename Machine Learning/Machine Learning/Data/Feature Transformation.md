---
title: Feature Transformation
tags:
draft: "false"
---
# Feature Transformation
Feature transformation is a way that we can take our original data, and convert it into something which tends to perform much better with our models. If we take in a bunch of features, and we want to move them down into something more useable. For example things like the [[Z-score]] is one such algorithm that workout pretty, feature transformation is important significantly helps out the data. 

We may want to meet some of the assumptions of the algorithm, like for instance the spiral data set and maybe a linear function, we can handle non linear relationships, different types like DFS scale features appropriately. 

2 basic ways of scaling, min/max scaling and standardization. Standardization makes mean 0 and standard dev 1. 

Categorical transformations, one hot encodding, for every column, convert it to a vector. For is ntnace if we have red,gren,blue, we can turn these into 1,0,0 0,1,0, or 0,0,1 also label encoding. 

Non linear transformations. Consider the sin example, instead of just doing least squarw fits, then we might be able to examine other featues of the data maybe the 
non linear ts all polynomial combinations of features wkth a level of cooo compa

$k$th order polymomial features, on one cariable, find the weight on x0,x1,2,xx2,x3 vanermonde marix and solve basically as we get mor and more complicated transforms we ask how does thsis change our ability to itneracte with, does adding neew featute s reall y mean that you are bettering your ttes sorethis would b liek at 

Say we have data [x1,x2] but we wa ntt this dara toin terac with the diffeerent aues of the vector. 
If we have x1,x,xq_{2}, we can find squares diff things, revealmore tendencies of our code, can exprsess more cplicated models 

fit trnsroma re gpod, we take 1 set and test it vs its own validation set 
but idea tothis to 

Similar idea appies to logs gaussian elim etc 